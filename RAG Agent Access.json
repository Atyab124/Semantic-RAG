{
  "name": "RAG Agent Access",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "id": "b24b05a7-d802-4413-bfb1-23e1e76f6203",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        360,
        20
      ],
      "webhookId": "a889d2ae-2159-402f-b326-5f61e90f602e"
    },
    {
      "parameters": {
        "content": "## Start by saying 'hi'\n![Button](https://i.imgur.com/PrIBJI6.png)",
        "height": 149,
        "width": 150
      },
      "id": "5592c045-6718-4c4e-9961-ce67a251b6df",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        180,
        -40
      ]
    },
    {
      "parameters": {
        "agent": "conversationalAgent",
        "options": {
          "systemMessage": "You are a RAG-powered AI assistant. First, try to answer confidently using your general knowledge. If you encounter a question you can’t answer with high confidence, reply with: @@NEED_CONTEXT@@. This will trigger a semantic search into the Supabase vector database to retrieve relevant document chunks. Once context is provided, use it to generate an accurate, grounded response. If no relevant documents are found, politely let the user know you don’t have enough information to answer."
        }
      },
      "id": "41174c8a-6ac8-42bd-900e-ca15196600c5",
      "name": "Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        580,
        20
      ]
    },
    {
      "parameters": {
        "model": "llama3.1:latest",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        540,
        240
      ],
      "id": "11ff6560-c7c0-4dfc-84bc-1290fec65d35",
      "name": "Ollama Chat Model",
      "credentials": {
        "ollamaApi": {
          "id": "mi5KTnPEDFxHdRBu",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        700,
        240
      ],
      "id": "dcdd1fbe-ce9a-4b91-abdb-cc83f33b3124",
      "name": "Postgres Chat Memory",
      "credentials": {
        "postgres": {
          "id": "uS3QVGQM8ltH60tU",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "retrieves relevant information from a Supabase vector database by matching the user’s query against stored content embeddings. Use this tool only when you don’t have a confident answer to the user’s question. It helps ground your response in previously stored documents (like notes or knowledge base entries) to ensure accuracy and context relevance.",
        "tableName": {
          "__rl": true,
          "value": "documents",
          "mode": "list",
          "cachedResultName": "documents"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "typeVersion": 1.3,
      "position": [
        860,
        200
      ],
      "id": "50cfbc1c-a690-4f03-afb8-ef1f348b8479",
      "name": "Supabase Vector Store1",
      "credentials": {
        "supabaseApi": {
          "id": "gFBq3cj1v4g40eAr",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "model": "nomic-embed-text:latest"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "typeVersion": 1,
      "position": [
        1040,
        360
      ],
      "id": "603c620a-5cd2-4007-8d28-ac5c6c7ed7ca",
      "name": "Embeddings Ollama",
      "credentials": {
        "ollamaApi": {
          "id": "mi5KTnPEDFxHdRBu",
          "name": "Ollama account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Supabase Vector Store1": {
      "ai_tool": [
        [
          {
            "node": "Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Ollama": {
      "ai_embedding": [
        [
          {
            "node": "Supabase Vector Store1",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "e36f36eb-5136-4f4f-b701-ebbfbbf88d0c",
  "meta": {
    "templateId": "self-building-ai-agent",
    "templateCredsSetupCompleted": true,
    "instanceId": "8e9fa353229a6d64532200f38fc6f9df4be5aeab12eefe769d488aa74309dbf9"
  },
  "id": "9S0rJIJc9XTEtVbI",
  "tags": []
}